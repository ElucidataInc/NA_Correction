import os
import sys

import numpy as np
import pandas as pd
import pubchempy as pcp
import time

import constants as cs


dir_path = os.path.dirname(os.path.realpath(__file__))
dat_tim = time.strftime(cs.DATE_TIME)


def check_file_exist(path):
    """
    This function validates the path of file and raises
    error upon failure.
    :param path: path to input file.
    :return: Raises error upon failure.
    """
    if os.path.exists(path) == False:
        raise IOError(cs.ERR_FILE_DOESNOT_EXIST_MSG)


def check_empty_dataframe(input_df):
    """
    This function validates that the dataframe is not
    empty and raises an error upon failure.
    :param input_df: input Dataframe
    :return: raises error upon failure
    """
    if input_df.empty:
        raise IOError(cs.ERR_DF_EMPTY_MSG)


def get_readfile_func(path):
    """
    This functions fetches the extension of the file to
    be read and maps it to the corresponding read function
    in pandas.
    :param: path of the input file
    :return: Read function of pandas according to
             file extension.
    """
    file_ext = os.path.splitext(path)[1]
    read_func = cs.EXT_DICT.get(file_ext)
    if read_func == None:
        raise IOError(cs.ERR_FILE_EXTN_MSG)
    return read_func


def read_file(path):
    """
    This function reads the input file in xls, xlsx, txt and csv
    format and returns a dataframe.
    Param:path : path to input file
    Returns:input_file_df : input file in the form of pandas dataframe
    """
    check_file_exist(path)
    if os.stat(path).st_size == 0:
        raise IOError(cs.ERR_EMPTY_FILE_MSG)
    else:
        read_function = get_readfile_func(path)
        input_file_df = read_function(path, header=0, index_col=False)
    check_empty_dataframe(input_file_df)
    return input_file_df


def check_no_formula_column_exist(input_df):
    """
    This function checks if the Formula column
    exists in the dataframe.
    Param: input_df: Input dataframe
    Return: Boolean (True or False)
    """

    return cs.FORMULA_COLUMN not in input_df.columns

def check_no_label_column_exist(input_df):
    """
    This function checks if the label column
    exists in the dataframe.
    Param: input_df: Input dataframe
    Return: Boolean (True or False)
    """
    return cs.SMALL_L_LABEL_COLUMN not in input_df.columns


def fetch_chemical_formula_web(compound_name):
    try:
        for compound in pcp.get_compounds(compound_name, 'name'):
            c = pcp.Compound.from_cid(compound.cid)
            return c.molecular_formula
    except ValueError:
        return None


def fetch_chemical_formula(compound_name):
    """
    Fetch formula of the given compound name from the formula file, if not present in the
    formula file then conduct a web search.
    :param compound_name: name of the compound whose formula is to be fetched
    :return: formula of the compound
    """
    path = os.path.join(dir_path, cs.CHEMICAL_FORMULA_FILE)
    formula_df = pd.read_csv(path)
    compound_details = formula_df[formula_df.Name == compound_name]\
        [cs.CHEMICAL_FORMULA_COLUMN].get_values()

    try:
        chemical_formula = compound_details[0]
        return chemical_formula
    except IndexError:
        return fetch_chemical_formula_web(compound_name)


def check_columns(input_df):
    """
    This function validates the presence of required columns in the input file.
    It raises error upon failure.
    :param input_df: Dataframe of the input file
    :return: raises error if required columns are not present.
    """
    set_required = set(cs.REQUIRED_COL_LIST)
    set_df = set(list(input_df))
    if set_required.issubset(set_df) == False:
        raise IOError(cs.ERR_MISSING_COL_MSG)


def check_column_headers(col_headers,col_names):
    """
    This function verifies that all default columns are present in input text files
    Args :
        col_headers : Column headers which are present in the dataframe
        col_names : Column headers for which we need to check if they are present or not
    return:
        error message if col_names is not subset of col_headers, else do nothing
    """
    err_msg = """Required column/s not found, Column: {!r}""". \
        format(list(set(col_names) - set(col_headers)))
    assert set(col_names).issubset(set(col_headers)),err_msg


def remove_cit(df,col_name):
    """
    This function replaces all the 'G9 0min cit', with 'G9 0min' in column 'Sample'. it is
    specifically of El-MAVEN output of MIMOSA experiment
    Args:
        df : dataframe
        col_name : name of column where it would search for the string
    return:
        updated column with 'cit' removed
    """
    df[col_name] = df[col_name].str.replace(' cit','')
    return df[col_name]


def write_to_csv(input_file_path,file_name,df):
    """
    This function will be used to generate an csv file
    Args:
        dir: current working directory
        file : name of output csv file
        df : dataframe which would be written in the csv file
    return:
        csv file after writing dataframe
    """
    dir = os.path.dirname(input_file_path)
    na_in = os.path.join(dir, file_name)
    df.to_csv(na_in,sep=',',header=True,index=False)
    return na_in


def rename_columns(df,old_name,new_name):
    """
    This function will rename column names
    Args:
        df : dataframe on which col names needs to be changed
        old_name : Old column names
        new_name : New column names
    return:
        Changes the requested col names and returns the updated dataframe
    """
    if len(old_name) == 0:
        df = df.rename(columns={old_name: new_name},inplace=True)
    else:
        df = df.rename(columns=dict(zip(old_name,new_name)),inplace=True)
    return df


def get_uniques_values(df,col_name):
    """
    This function will extract all the unique values from the column of a dataframe
    Args:
        df : Dataframe
        col_name : Column name from where unique values will be extracted
    return:
        list of all the unique values in that column
    """
    unique_val = np.unique(df[[col_name]].values)
    return unique_val


def filter_col(df,col_name,text):
    """
    This function will filter the column in a dataframe on the basis of text provided by user
    Args:
        df: dataframe
        col_name: Column name where it would apply filter
        text: text with which it would apply the filter
    return:
        filtered column
    """
    new_df = df.loc[df[col_name] == text]
    return new_df


def get_mass_info(dir):
    """Creates 'Mass Info' column which is mandatory for NA Correction from MIMOSA Compound
    Database stored in data_files
    Constants:
    MASS_INFO1 = 'precursorMz'
    MASS_INFO2 = 'productMz'
    MASS_INFO = 'Mass Info'
    Args:
    dir : Current working directory
    return :
    It returns a dataframe containing Mass Info of all the components
    """
    path = os.path.join(dir, cs.COMP_DATA)
    comp_data_df = pd.read_csv(path, header=0, index_col=False)
    rename_columns(comp_data_df, [cs.MVN_COL[0]], [cs.NA_COL[0]])
    comp_data_df[cs.MASS_INFO1] = comp_data_df[cs.MASS_INFO1].astype('float64')
    comp_data_df[cs.MASS_INFO2] = comp_data_df[cs.MASS_INFO2].astype('float64')
    comp_data_df[cs.MASS_INFO] = comp_data_df.apply(
        lambda x: '%s / %s' % (x[cs.MASS_INFO1], x[cs.MASS_INFO2]), axis=1)
    mass_info = comp_data_df[[cs.NA_COL[0], cs.MASS_INFO]]
    return mass_info


def get_method_type(dir):
    """
    This function would read "metadata_mq_with_method_all.xlsx" and then create a dataframe for
    method type ofl different metabolites and then merges it with mass_info dataframe creating
    mass_info_with_method_df
    Args:
        dir: Current working directory
    return:
        mass_info_with_method_df dataframe
    """
    path = os.path.join(dir, cs.METADATA_FILE)
    metadata_df = pd.read_excel(path, header=0)
    method_df = metadata_df[cs.METADATA_COL]
    method_df[cs.METADATA_COL[1]] = method_df[cs.METADATA_COL[1]].astype(str)
    return method_df


def add_missing_comp(df, method):
    """
    This function would search for missing 'Component Name' in each filename present in 'Original
    Filename' column, and then add additional rows containing required information for the missing
    'Component Name' in the dataframe.
    'Component Name' : Column name in the dataframe, containing different components of a fragment
    Constants :
    NA_COL = ['Component Name', 'Original Filename', 'Area']
    Args:
        df : dataframe on which this function would be applied
        method : 'Method type' which would be entered in the newly added row
    Return:
        New dataframe after adding missing components
    """
    df.reset_index(inplace = True, drop = True)
    uniq_comp = get_uniques_values(df, cs.NA_COL[0])
    uniq_file = get_uniques_values(df, cs.NA_COL[1])
    col_names = cs.NA_COL + [cs.METADATA_COL[1]]
    df_new = pd.DataFrame(data=None,columns=col_names)
    for file in uniq_file:
        df_file = filter_col(df, cs.NA_COL[1], file)
        uniq_comp_in_file = get_uniques_values(df_file, cs.NA_COL[0])
        if set(uniq_comp) - set(uniq_comp_in_file) == set([]):
            pass
        else:
            miss_comp = list(set(uniq_comp) - set(uniq_comp_in_file))
            for i in range(len(miss_comp)):
                df.loc[len(df.index)] = [miss_comp[i], file, 0.00, method]

    df_new = pd.concat([df_new, df])
    return df_new


def remove_column_from_df(df, column_name):
    df = df.drop(column_name, axis=1)
    return df


def replace_kegg_with_hmdb(df, kegg_list):
    """
    This function checks for kegg id in dataframe and returns its hmdb id if
    present in dataframe

    :param df: (Dataframe) Having information of KEGG, HMDB and Metabolite name
    :param kegg_list: (list) list of keggID
    :return: Returns list of hmdb corresponding to kegg
    """
    hmdb = []
    for item in kegg_list:
        temp = ""
        for index, rows in df.iterrows():
            if item == rows[cs.KEGG_COLUMN]:
                temp = rows[cs.HMDBID_COLUMN]
        if temp == "":
            hmdb.append(item)
        else:
            hmdb.append(temp)
    return hmdb
