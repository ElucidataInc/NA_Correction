import os
import pandas as pd
import time

import constants as const
import helpers as hlp

pd.options.mode.chained_assignment = None
dat_tim = time.strftime(const.DATE_TIME)
dir_path = os.path.dirname(os.path.realpath(__file__))

def convert_file_LCMS(input_file_path):
    """
    This function reads input file and convert it into a dataframe.
    Modify dataframe according to NA correction tool :  Rename columns,
    add formula column, drop columns.
    Write dataframe into a csv file.
    :param input_file_path: path to input file.
    :return: list of path of .csv file compatible to NA correction tool.
    """
    input_df = hlp.read_file(input_file_path)

    if hlp.check_no_label_column_exist(input_df):
        input_df[const.SMALL_L_LABEL_COLUMN] = None

    else:
        try:
            input_df = input_df[input_df[const.SMALL_L_LABEL_COLUMN] != "b"]
        except:
            pass

    hlp.check_columns(input_df)
    input_df = hlp.remove_column_from_df(input_df, const.SMALL_L_LABEL_COLUMN)
    input_df = input_df.rename(
        columns={const.NOTE_COLUMN: const.LABEL_COLUMN, const.COMPOUND_COLUMN: const.NAME_COLUMN})

    if hlp.check_no_formula_column_exist(input_df):
        input_df[const.FORMULA_COLUMN] = input_df[const.NAME_COLUMN].apply(hlp.fetch_chemical_formula)
        input_df.rename(columns = {const.FORMULA_COLUMN : 'Formula'}, inplace=True)
    else:
        input_df.rename(columns = {const.FORMULA_COLUMN : 'Formula'}, inplace=True)

    input_df.drop(const.EXTRA_COLUMNS_LIST, axis=1, inplace=True)
    input_df.dropna()
    return input_df


def convert_file_MSMS(input_file_path):
    """
    This function takes the path of the input file that is to be converted.
    it takes raw_df as input,and then after checking for the required col names
    performs various operations required to convert data to be NA Correction-ready,
    i.e., renaming columns, removing strings, merging
    dataframes, thus resulting into a final dataframe which is then broken in sub-dataframes on the
    basis of 'Method-Type', these dataframes are then further exported to .csv file
    :param input_file_path: path to input file.
    :return: list of paths of .csv file compatible to NA correction tool.
    """
    input_df = hlp.read_file(input_file_path)
    col_headers = input_df.columns.tolist()
    hlp.check_column_headers(col_headers, const.MVN_COL)
    hlp.rename_columns(input_df, const.MVN_COL, const.NA_COL)
    input_df[const.NA_COL[1]] = hlp.remove_cit(input_df, const.NA_COL[1])
    mvn_df = input_df[const.NA_COL]
    mvn_df = mvn_df[~mvn_df[const.NA_COL[1]].str.contains("std")]
    mvn_method_df = hlp.get_method_type(dir_path)
    merged_df = pd.merge(mvn_df, mvn_method_df, on=const.NA_COL[0])
    unique_method_list = hlp.get_uniques_values(merged_df, const.METADATA_COL[1])
    path_list = []
    converted_df = []
    for each_method in unique_method_list:
        df_method = hlp.filter_col(merged_df, const.METADATA_COL[1], each_method)
        df_method = hlp.add_missing_comp(df_method, each_method)
        df_mass_info = hlp.get_mass_info(dir_path)
        df_final = pd.merge(df_method, df_mass_info, on=const.NA_COL[0])
        output_file_name = const.OUTPUT_FILE + each_method + const.CSV_EXT
        csv_output = hlp.write_to_csv(input_file_path, output_file_name, df_final)
        converted_df.append(df_final)
    return converted_df


def convert_msms_quant(input_file_path):
    """
    This function converts LCMS/MS maven output to quant compatible
    input
    :param input_file_path: path of the file to be converted
    :return: quant compatible dataframe
    """
    input_df = hlp.read_file(input_file_path)

    if const.FORMULA_COLUMN in input_df:
        input_df = hlp.remove_column_from_df(input_df, const.FORMULA_COLUMN)
    elif const.UPPERCASE_FORMULA_COLUMN in input_df:
        input_df = hlp.remove_column_from_df(input_df, const.UPPERCASE_FORMULA_COLUMN)

    col_headers = input_df.columns.tolist()
    hlp.check_column_headers(col_headers, const.MVN_COL)
    hlp.rename_columns(input_df, const.MVN_COL, const.NA_COL)
    input_df[const.NA_COL[1]] = hlp.remove_cit(input_df, const.NA_COL[1])
    mvn_df = input_df[const.NA_COL]
    df_mass_info = hlp.get_mass_info(dir_path)
    mvn_df_1 = pd.merge(mvn_df, df_mass_info, on=const.NA_COL[0])
    mvn_df_1[const.SAMPLE_NAME] = mvn_df_1[const.NA_COL[1]]
    return mvn_df_1


def convert_lcms_quant(input_file_path):
    """
    This function converts LCMS maven output to quant compatible input.
    :param input_file_path: path of the file to be converted
    :return: quant compatible dataframe
    """
    input_df = hlp.read_file(input_file_path)

    if const.FORMULA_COLUMN in input_df.columns:
        input_df = hlp.remove_column_from_df(input_df, const.FORMULA_COLUMN)
    elif const.UPPERCASE_FORMULA_COLUMN in input_df.columns:
        input_df = hlp.remove_column_from_df(input_df, const.UPPERCASE_FORMULA_COLUMN)

    hlp.check_columns(input_df)
    input_df = input_df.rename(columns={const.COMPOUND_COLUMN: const.NA_COL[0]})
    input_df.drop(const.EXTRA_COLUMNS_LIST_QUANT, axis=1, inplace=True)
    input_df.dropna()
    input_df = pd.melt(input_df, id_vars=[const.NA_COL[0]], var_name=const.NA_COL[1],
                       value_name=const.NA_COL[2])
    input_df[const.SAMPLE_NAME] = input_df[const.NA_COL[1]]
    input_df[const.MASS_INFO] = 0
    return input_df


def convert_maven_to_sample_qc(input_file_path):
    """
    This function converts the maven output file into a
    file format compatible with sample qc input requirement.
    :param input_file_path: path of the file to be converted
    :return: sample_qc compatible dataframe
    """
    input_df = hlp.read_file(input_file_path)
    hlp.check_columns(input_df)
    input_df.drop(const.EXTRA_COLUMNS_LIST_SAMPLE_QC, axis=1, inplace=True)
    input_df.dropna()
    input_df[const.SAMPLE_ID] = input_df[const.NOTE_COLUMN] + input_df[const.COMPOUND_COLUMN]
    input_df.drop([const.NOTE_COLUMN, const.COMPOUND_COLUMN], axis=1, inplace=True)
    list_cols = input_df.columns.tolist()
    sample_col_first_list = list_cols[-1:] + list_cols[:-1]
    input_df = input_df[sample_col_first_list]
    input_df = input_df.set_index(const.SAMPLE_ID).transpose()
    input_df.index.name = const.SAMPLE_ID
    input_df = input_df.reset_index()

    return input_df


def convert_maven_to_unlabelled_pvd(input_file_path):
    """
    This function converts LCMS maven output to metscape compatible input.

    :param input_file_path: (string) path of the file to be converted
    :return: (dataframe) Metscape compatible df
    """
    input_df = hlp.read_file(input_file_path)
    path = os.path.join(dir_path, const.COMP_HMDB_FILE)
    metadata_df = pd.read_csv(path)
    hlp.check_columns(input_df)
    df = input_df.dropna(how='all')
    if not df[const.SMALL_L_LABEL_COLUMN].isnull().all():
        df = df[df[const.SMALL_L_LABEL_COLUMN] == "g"]
    good_peak_df = df[df[const.COMPOUNDID_COLUMN].str.contains(const.HMDB)]
    hmdb_index = df.index.difference(good_peak_df.index)
    left_df = df.ix[hmdb_index, :]
    kegg_df = left_df[left_df[const.COMPOUNDID_COLUMN].str.contains("^C[0-9]{5,"
                                                                 "}$")]
    kegg_list = list(kegg_df[const.COMPOUNDID_COLUMN])
    hmdb_list = hlp.replace_kegg_with_hmdb(metadata_df, kegg_list)
    for f, b in zip(kegg_list, hmdb_list):
        kegg_df[const.COMPOUNDID_COLUMN].replace(to_replace=f, value=b, inplace=True)
    final = pd.concat([good_peak_df, kegg_df], ignore_index=True)
    sample_df = final.filter(
        regex='(q|Q)(c|C)|(s|S)(t|T)(d|D)|(b|B)(l|L)(a|A)(n|N)('
              'k|K)|(b|B)(k|K)').columns.tolist()
    sample_df = final.drop(sample_df, axis=1)
    sample_df = sample_df.drop(const.EXTRA_COLUMNS_LIST_UL_PVD, axis=1)
    sample_df = sample_df[sample_df[const.COMPOUNDID_COLUMN].str.contains(const.HMDB)]
    sample_df[const.MEAN] = sample_df.mean(axis=1)
    sample_df = sample_df.sort_values(by=[const.COMPOUNDID_COLUMN])
    idx = sample_df.groupby([const.COMPOUNDID_COLUMN])[const.MEAN].transform(max) == \
          sample_df[const.MEAN]
    sample_df = sample_df[idx]
    sample_df = sample_df.drop([const.MEAN], axis=1)
    sample_df.set_index(const.COMPOUNDID_COLUMN, inplace=True)
    final_df = sample_df.transpose()
    final_df.index.name = const.SAMPLE_ID
    final_df = final_df.reset_index()
    return final_df


def conversion(inputfile, filetype):
    """
    This function the file type to the function which i used for conversion.
    :param inputfile: file to be converted
    :param filetype: conversion type
    :return: converted data frame
    """

    function = const.CONVERSION_DICT.get(filetype)
    converted_df = globals()[function](inputfile)
    return converted_df

