import os

from olmonk import ConfigDataValidator as CDV
from olmonk import helpers as hlp
import pandas as pd

import constants as const
import custom_exceptions


@custom_exceptions.handleError
def validate_input_file(path):
    """
    This is the function for checking basic validation of file.
    If any exception raises during validation check , handleError
    decorator will catch it and processed accordingly.
    Parameters
    ----------
    path : string
        path of file
    Returns
    -------
    :return: True, if no exception is raised
    """

    if not os.path.isfile(path):
        raise custom_exceptions.FileExistError

    if os.stat(path).st_size == 0:
        raise custom_exceptions.FileEmptyError

    return True


@custom_exceptions.handleError
def read_file(input_file_path):
    """This function reads the input file in xls, xlsx,
    txt and csv format
    Parameters
    ----------
    input_file_path : string
        path of input file
    Returns
    -------
    df : input file dataframe after reading the file
    """

    if os.path.splitext(input_file_path)[1] in const.EXCEL_FILES:
        df = pd.read_excel(input_file_path, header=0)

    elif os.path.splitext(input_file_path)[1] == const.CSV_FILE:
        df = pd.read_csv(input_file_path, header=0)

    elif os.path.splitext(input_file_path)[1] == const.TXT_FILE:
        df = pd.read_table(input_file_path, header=0)

    else:
        raise custom_exceptions.FileExtensionError

    return df


def fill_missing(df):
    """
    To fill Missing values with 0 in the dataframe.

    Parameters
    ----------
    df : dataframe
        dataframe to be checked
    Returns
    -------
    dataframe filled with 0
    """
    return df.fillna(0)


def missing_data_report(missing_df, logs):
    """
    Log the information with action and message

    Parameters
    ----------
    missing_df : dataframe
        dataframe to be checked
    Returns
    -------
    Dict : logs of errors and warnings
    """

    for index, row in missing_df.iterrows():
        logs[const.WARNINGS][const.MESSAGE].append(
            const.ROW_NUMBER + ' ' + str(row[const.ROW_NUMBER_COLUMN]) + ': column'
            + ' ' + row[const.COLUMN_NAME] + ' ' + 'has missing value'),

        logs[const.WARNINGS][const.ACTION].append(const.ACTION_MSG)

    return logs

@custom_exceptions.handleError
def check_file_type(df):
    """
    Validated the maven file dataframe as per the basic
    and advanced checks in olmonk.

    Parameters
    ----------
    df : pandas dataframe
        maven output dataframe

    Returns
    -------
    returns the file type according to instrument used
    """

    column_list = df.columns.tolist()
    if set(const.REQUIRED_COL_LIST_MSMS).issubset(set(column_list)):
        return const.MSMS
    elif set(const.MAVEN_REQUIRED_COL_LIST).issubset(set(column_list)):
        return const.MS
    else:
        raise custom_exceptions.InvalidMavenError


def check_maven_df_with_olmonk(path):
    """
    Validated the maven file dataframe as per the basic
    and advanced checks in olmonk.

    Parameters
    ----------
    path : string
        path
    Returns
    -------
    returns the corrected dataframe and the logs after validation
    """
    maven_dict = dict(const.DICT_READ_MAVEN_FILE)
    maven_dict[const.FILE_PATH] = path
    df = hlp.get_df(path)
    column_list = df.columns.tolist()
    file_type = check_file_type(df)
    if file_type == const.MS:
        numerical_columns = list(set(column_list) - set(const.MAVEN_REQUIRED_COL_LIST))
        missing_df = hlp.check_missing(df[numerical_columns[1:]])
        fill_missing(df[numerical_columns[1:]])
        maven_dict[const.FUNCTIONS][const.NUMERICAL][
            const.COLUMN_LIST] = numerical_columns
    else :
        numerical_column = [const.PEAK_AREA_CORRECTED]
        maven_dict[const.FUNCTIONS][const.NUMERICAL][
            const.COLUMN_LIST] = numerical_column
        missing_df = pd.DataFrame(columns=[const.ROW_NUMBER_COLUMN, const.COLUMN_NAME,
                                           const.STATE])
    cdv = CDV(maven_dict)
    cdv.validate()
    logs = missing_data_report(missing_df, cdv.dv.logs)
    return cdv.dv.corrected_df, logs


def find_extra_components(maven_comp_list, src_list):
    """
    This function returns the components which are not in the
    database to create the mapping file. Returns the missing
    components.

    Args:
    -----
        maven_comp_list: list
            component names list
        src_list: list
            source list component names
    Return:
    -------
        list of diff component names
    """
    diff = set(maven_comp_list) - set(src_list)
    return list(diff)


def find_missing_components(component_list, current_component_list):
    """
    This function returns the components which are not in the
    database to create the mapping file. Returns the missing
    components in the form required in Quant.

    Args:
    -----
        component_list: list
            component names list

    Return:
    -------
        list of dicts of missing component names
    """
    output_dict_list = []
    src_list = current_component_list
    diff  = list(set(component_list) - set(src_list))
    for compound in diff:
        temp_dict = {const.COMPONENT_NAME: compound,
                     const.UNLABELED_FRAGMENT: ""}
        output_dict_list.append(temp_dict)

    return output_dict_list


def find_missing_components_na(component_list, current_component_list):
    """
       This function returns the components which are not in the
       database to create the mapping file. Returns the missing
       components according to Isocorrect application.

       Args:
       -----
           component_list: list
               component names list

       Return:
       -------
           list of dicts of missing component names
       """
    output_dict_list = []
    src_list = current_component_list
    diff  = list(set(component_list) - set(src_list))
    for compound in diff:
        temp_dict = {const.COMPONENT_NAME: compound,
                     const.UNLABELED_FRAGMENT: "",
                     const.FORMULA: "",
                     const.ISOTOPIC_TRACER: "",
                     const.PARENT_FORMULA: ""}
        output_dict_list.append(temp_dict)

    return output_dict_list


def is_maven_file(df):
    """
    This function checks if the file is a maven file
    or not.
    Args:
    -----
        df: Dataframe
            input file dataframe
    Return:
    -------
        Boolean if it is maven file or not
    """
    set_required = set(const.MAVEN_REQUIRED_COL_LIST)
    set_df = set(list(df))
    return set_required.issubset(set_df)


def check_df_type(df):
    """
    This function checks if the file is a MSMS file
    or MS file.
    Args:
    -----
        df: Dataframe
            input file dataframe
    Return:
    -------
        String: MS or MSMS
    """
    if len(df[const.MASS_INFO].unique()) == 1:
        return const.MS
    else:
        return const.MSMS


def append_row_from_json(df, data_dict):
    """
    This function appends the rows from the data_dicionary
    to the dataframe passed.

    data_dict = [{'component_name': 'fragment_name'}]
    Args:
    -----
        df: Dataframe
            input file dataframe
        data_dict: list of dictionary
            metadata containing mapping data

    Return:
    -------
        Edited dataframe
    """
    new_df = pd.DataFrame(data_dict)
    appended_df = df.append(new_df)
    return appended_df
